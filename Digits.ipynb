# Import necessary libraries
from keras.models import Sequential  # Sequential model from Keras
from keras.layers import Dense, Conv2D, Flatten, MaxPool2D  # Importing layers for CNN
from keras.datasets import mnist  # Importing the MNIST dataset
from keras.utils import to_categorical  # Utility for one-hot encoding
import numpy as np  # Importing NumPy for numerical operations
import matplotlib.pyplot as plt  # Importing Matplotlib for visualization

# Load the data and split it into train and test
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Get the image shape and print it to understand the data dimensions
print(X_train.shape)  # Output: (60000, 28, 28)
print(X_test.shape)   # Output: (10000, 28, 28)

# Visualize an example from the training set
plt.imshow(X_train[402], cmap='gray')  # Displaying the 402nd image in grayscale
plt.show()

# Reshaping the data to fit the model (adding the channel dimension)
X_train = X_train.reshape(60000, 28, 28, 1)
X_test = X_test.reshape(10000, 28, 28, 1)

# One-Hot Encoding of the target labels to convert them into categorical format
y_train_one_hot = to_categorical(y_train)
y_test_one_hot = to_categorical(y_test)

# Print the first one-hot encoded label to verify the transformation
print(y_train_one_hot[0])  # Example output: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]

# Build the CNN model
model = Sequential()
# Add convolutional layer with 64 filters, 3x3 kernel, ReLU activation, and input shape of 28x28x1
model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))
# Add another convolutional layer with 32 filters and ReLU activation
model.add(Conv2D(32, kernel_size=3, activation='relu'))
# Add max pooling layer to reduce spatial dimensions
model.add(MaxPool2D(pool_size=(2, 2), strides=None, padding='valid'))
# Flatten the output to connect to the dense layer
model.add(Flatten())
# Add a dense (fully connected) layer with 10 output neurons for classification
model.add(Dense(10, activation='softmax'))

# Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model for 10 epochs with validation on the test set
hist = model.fit(X_train, y_train_one_hot, validation_data=(X_test, y_test_one_hot), epochs=10)
